import torch

# info from pytorch
torch_activations = [
    "threshold", "relu", "hardtanh", "relu6", "elu", "selu", "celu", "leaky_relu",
    "prelu", "rrelu", "glu", "logsigmoid", "hardshrink", "tanhshrink", "softsign",
    "softplus", "softmin", "softmax", "softshrink", "gumbel_softmax", "log_softmax",
    "tanh", "sigmoid"
]



